set.seed(1)
nn <- neuralnet(high_quality + intermediate_quality + low_quality ~ ., data = train_norm_dummy_df[, -11], hidden = i, linear.output = FALSE, threshold = 0.2)
valid_pred_nn <- data.frame(predict(nn, valid_norm_dummy_df[, -c(11, 12, 13, 14)]))
names(valid_pred_nn)[1:3] <- c("High", "Intermediate", "Low")
valid_pred_nn$Prediction <- NA
for(j in 1:length(valid_pred_nn$High)) {
valid_pred_nn[j, 4] <- names(which.max(valid_pred_nn[j, 1:3]))
}
nn.cm <- confusionMatrix(as.factor(valid_pred_nn$Prediction),valid_norm_df$binned_quality)
nn_nodes_2[i-1, 2] <- nn.cm[["overall"]][["Kappa"]]
nn_nodes_2[i-1, 3] <- (nn.cm$byClass[3,1] + nn.cm$byClass[2,1] + nn.cm$byClass[1,1]) / 3
}
nn_nodes_2
nn_nodes_1 <- data.frame("number_nodes" = seq(from= 2, to = 10), "kappa_value" = NA, "balanced_accuracy" = NA)
for (i in 2:10){
set.seed(1)
nn <- neuralnet(high_quality + intermediate_quality + low_quality ~ ., data = train_norm_dummy_df[, -11], hidden = i, linear.output = FALSE, threshold = 0.1)
valid_pred_nn <- data.frame(predict(nn, valid_norm_dummy_df[, -c(11, 12, 13, 14)]))
names(valid_pred_nn)[1:3] <- c("High", "Intermediate", "Low")
valid_pred_nn$Prediction <- NA
for(j in 1:length(valid_pred_nn$High)) {
valid_pred_nn[j, 4] <- names(which.max(valid_pred_nn[j, 1:3]))
}
nn.cm <- confusionMatrix(as.factor(valid_pred_nn$Prediction),valid_norm_df$binned_quality)
nn_nodes_1[i-1, 2] <- nn.cm[["overall"]][["Kappa"]]
nn_nodes_1[i-1, 3] <- (nn.cm$byClass[3,1] + nn.cm$byClass[2,1] + nn.cm$byClass[1,1]) / 3
}
nn_nodes_1
rm(list = ls())
library(naniar)
library(ggplot2)
library(reshape2)
library(magrittr)
library(dplyr)
library(car)
library(GGally)
library(viridis)
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(rpart)
library(rpart.plot)
library(adabag)
library(randomForest)
library(imbalance)
library(e1071)
library(neuralnet)
# setwd("~/GitHub/CVTDM_Project")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
sapply(wine, function(x) length(unique(x)))
wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
ifelse(wine$quality >= 7, "High", "None"))))
wine$quality = as.factor(wine$quality)
rm(list = ls())
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(imbalance)
library(e1071)
setwd("C:/Users/Sam/Desktop/Data Mining/Project methods")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
ifelse(wine$quality >= 7, "High", "None"))))
wine$quality = as.factor(wine$quality)
logwine = wine[,-c(8,12)]
logwine[,-c(3,7,8,11)] = lapply(logwine[,-c(3,7,8,11)], log)
install.packages("nnet")
library(nnet)
rm(list = ls())
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(imbalance)
library(e1071)
library(nnet)
setwd("C:/Users/Sam/Desktop/Data Mining/Project methods")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
ifelse(wine$quality >= 7, "High", "None"))))
wine$quality = as.factor(wine$quality)
logwine = wine[,-c(8,12)]
logwine[,-c(3,7,8,11)] = lapply(logwine[,-c(3,7,8,11)], log)
set.seed(1)
train_index = createDataPartition(logwine$binned_quality, p = .5, list = FALSE)
train_df = logwine[train_index,]
valid_test_df = logwine[-train_index,]
valid_index = createDataPartition(valid_test_df$binned_quality, p = .6, list = FALSE)
valid_df = valid_test_df[valid_index,]
test_df = valid_test_df[-valid_index,]
#initialize normalized training and validation data frames to the original ones
train_norm_df = train_df
valid_norm_df = valid_df
test_norm_df = test_df
#use PreProcess() from the caret package and predict() to normalize numerical variables
norm_values = preProcess(train_df[,-c(11)], method = "range")
train_norm_df[,-c(11)] = predict(norm_values, train_df[,-c(11)])
valid_norm_df[,-c(11)] = predict(norm_values, valid_df[,-c(11)])
test_norm_df[,-c(11)] = predict(norm_values, test_df[,-c(11)])
set.seed(1)
new_train_df = rwo(train_df, 400, "binned_quality")
os_train_df = rbind(train_df, new_train_df)
os_log_reg = multinom(binned_quality ~ ., data = os_train_df)
summary(os_log_reg)
os_log_prob = predict(os_log_reg, newdata = test_df, type = "p")
os_log_pred = data.frame("pred" = as.factor(colnames(os_log_prob)[apply(os_log_prob,1,which.max)]))
confusionMatrix(os_log_pred$pred, test_df[,11])
kappa = confusionMatrix(os_log_pred$pred, test_df[,11])$overall[2]
kappa
low_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[1,1]
intermediate_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[3,1]
balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
head_os_log_prob
head(os_log_prob)
rm(list = ls())
library(naniar)
library(ggplot2)
library(reshape2)
library(magrittr)
library(dplyr)
library(car)
library(GGally)
library(viridis)
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(rpart)
library(rpart.plot)
library(adabag)
library(randomForest)
library(imbalance)
library(e1071)
library(neuralnet)
library(nnet)
# setwd("~/GitHub/CVTDM_Project")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
sapply(wine, function(x) length(unique(x)))
wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
ifelse(wine$quality >= 7, "High", "None"))))
wine$quality = as.factor(wine$quality)
logwine = wine[,-c(8,12)]
logwine[,-c(3,7,8,11)] = lapply(logwine[,-c(3,7,8,11)], log) #log transform all variables except citric.acid, total.sulfure.dioxide, pH and binned_quality
head(logwine)
set.seed(1)
train_index = createDataPartition(logwine$binned_quality, p = .5, list = FALSE)
train_df = logwine[train_index,]
valid_test_df = logwine[-train_index,]
valid_index = createDataPartition(valid_test_df$binned_quality, p = .6, list = FALSE)
valid_df = valid_test_df[valid_index,]
test_df = valid_test_df[-valid_index,]
#initialize normalized training and validation data frames to the original ones
train_norm_df = train_df
valid_norm_df = valid_df
test_norm_df = test_df
#use PreProcess() from the caret package and predict() to normalize numerical variables
norm_values = preProcess(train_df[,-c(11)], method = "range")
train_norm_df[,-c(11)] = predict(norm_values, train_df[,-c(11)])
valid_norm_df[,-c(11)] = predict(norm_values, valid_df[,-c(11)])
test_norm_df[,-c(11)] = predict(norm_values, test_df[,-c(11)])
table(logwine$binned_quality)
prop.table(table(logwine$binned_quality))
set.seed(1)
add_train_df = rwo(train_df, 400, "binned_quality") # Generation of 400 instances
os_train_df = rbind(train_df, add_train_df) # Combining the new instances to the training set
os_train_norm_df = os_train_df
#use PreProcess() from the caret package and predict() to normalize numerical variables
os_norm_values = preProcess(os_train_df[,-c(11)], method = "range")
os_train_norm_df[,-c(11)] = predict(os_norm_values, os_train_df[,-c(11)])
#initialize a new data frame with three columns: k, accuracy, and balanced_accuracy
best_k_df = data.frame(k = seq(1, 50, 1), kappa = rep(0,50), balanced_accuracy = rep(0,50))
#perform knn on the validation set using different k then store accuracy and balanced accuracy for each k in the data frame
for(i in 1:50) {
knn_pred = knn(train = os_train_norm_df[,-11], test = valid_norm_df[,-11], cl = os_train_norm_df[,11], k = i)
best_k_df[i, 2] = confusionMatrix(knn_pred, valid_norm_df[,11])$overall[2]
low_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[1,1]
best_k_df[i, 3] = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
}
kappa_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=kappa), color="red") + theme_classic()
balanced_accuray_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=balanced_accuracy), color="blue") + theme_classic()
plot_grid(kappa_plot, balanced_accuray_plot, ncol = 1, align = "v")
which.max(best_k_df$kappa)#best k based on accuracy
which.max(best_k_df$balanced_accuracy)#best k based on balanced accuracy
os_log_reg = multinom(binned_quality ~ ., data = os_train_df)
summary(os_log_reg)
os_log_prob = predict(os_log_reg, newdata = test_df, type = "p")
os_log_pred = data.frame("pred" = colnames(os_log_prob)[apply(os_log_prob,1,which.max)])
os_log_pred$pred = as.factor(os_log_pred$pred)
confusionMatrix(os_log_pred$pred, test_df[,11])
kappa_logist = confusionMatrix(os_log_pred$pred, test_df[,11])$overall[2]
kappa_logist
low_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[1,1]
bal_acc_logist = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_logist
os_nb_model = naiveBayes (binned_quality ~ ., data = os_train_df)
os_nb_model
os_nb_pred = predict(os_nb_model, newdata = test_df, type = "class")
confusionMatrix(os_nb_pred, test_df[,11])
kappa_bayes = confusionMatrix(os_nb_pred, test_df[,11])$overall[2]
kappa_bayes
low_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[1,1]
bal_acc_bayes = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_bayes
set.seed(1)
tree1 <- rpart(binned_quality ~ ., data=os_train_df, method = "class", control = rpart.control(cp = 0, minsplit = 1, minbucket = 1, xval = 5))
# Look at the minimum standard error
printcp(tree1)
which.min(tree1$cptable[, 4])
# Take the cp associated with the minimum standard error to prune the tree:
set.seed(1)
pruned_tree1 <- prune(tree1, cp = tree1$cptable[which.min(tree1$cptable[, "xerror"]), "CP"])
prp(pruned_tree1)
# If we want to look at the most important variables:
pruned_tree1$variable.importance
# We can now predict the outcome:
pruned_tree1_pred_test <- predict(pruned_tree1, test_df, type="class")
pruned_tree1_cm <- confusionMatrix(pruned_tree1_pred_test, test_df$binned_quality)
pruned_tree1_cm
kappa_pruned_tree1 = pruned_tree1_cm$overall[2]
kappa_pruned_tree1
low_sensitivity = pruned_tree1_cm$byClass[3,1]
intermediate_sensitivity = pruned_tree1_cm$byClass[2,1]
high_sensitivity = pruned_tree1_cm$byClass[1,1]
bal_acc_pruned_tree1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_pruned_tree1
set.seed(1)
boost1 <- boosting(binned_quality ~ ., data=os_train_df, control = rpart.control(xval = 5))
boost1_pred_test <- predict(boost1, test_df, type="class")
boost1.cm <- confusionMatrix(as.factor(boost1_pred_test$class), test_df$binned_quality)
boost1.cm
kappa_boost1 = boost1.cm$overall[2]
kappa_boost1
low_sensitivity = boost1.cm$byClass[3,1]
intermediate_sensitivity = boost1.cm$byClass[2,1]
high_sensitivity = boost1.cm$byClass[1,1]
bal_acc_boost1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_boost1
ensemble_pred_df = data.frame("actual_value" = test_df$binned_quality,
"knn_pred" = best_knn_pred,
"log_pred" = os_log_pred$pred,
"nb_pred" = os_nb_pred,
"tree_pred" = pruned_tree1_pred_test,
"boosting_pred" = boost1_pred_test,
"bagging_pred" = bag1_pred_test,
"rf_pred" = rf1_pred_test,
"nnet_pred" = as.factor(test_pred_nn1$Prediction))
rm(list = ls())
library(naniar)
library(ggplot2)
library(reshape2)
library(magrittr)
library(dplyr)
library(car)
library(GGally)
library(viridis)
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(rpart)
library(rpart.plot)
library(adabag)
library(randomForest)
library(imbalance)
library(e1071)
library(neuralnet)
library(nnet)
# setwd("~/GitHub/CVTDM_Project")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
sapply(wine, function(x) length(unique(x)))
wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
ifelse(wine$quality >= 7, "High", "None"))))
wine$quality = as.factor(wine$quality)
logwine = wine[,-c(8,12)]
logwine[,-c(3,7,8,11)] = lapply(logwine[,-c(3,7,8,11)], log) #log transform all variables except citric.acid, total.sulfure.dioxide, pH and binned_quality
head(logwine)
set.seed(1)
train_index = createDataPartition(logwine$binned_quality, p = .5, list = FALSE)
train_df = logwine[train_index,]
valid_test_df = logwine[-train_index,]
valid_index = createDataPartition(valid_test_df$binned_quality, p = .6, list = FALSE)
valid_df = valid_test_df[valid_index,]
test_df = valid_test_df[-valid_index,]
#initialize normalized training and validation data frames to the original ones
train_norm_df = train_df
valid_norm_df = valid_df
test_norm_df = test_df
#use PreProcess() from the caret package and predict() to normalize numerical variables
norm_values = preProcess(train_df[,-c(11)], method = "range")
train_norm_df[,-c(11)] = predict(norm_values, train_df[,-c(11)])
valid_norm_df[,-c(11)] = predict(norm_values, valid_df[,-c(11)])
test_norm_df[,-c(11)] = predict(norm_values, test_df[,-c(11)])
# Initialize normalized training and validation data frames with dummies to the normalized ones
train_norm_dummy_df <- train_norm_df
valid_norm_dummy_df <- valid_norm_df
test_norm_dummy_df <- test_norm_df
# Creation of the vectors
train_norm_dummy_df$high_quality <- ifelse(train_norm_dummy_df$binned_quality == "High", 1, 0)
train_norm_dummy_df$intermediate_quality <- ifelse(train_norm_dummy_df$binned_quality == "Intermediate", 1, 0)
train_norm_dummy_df$low_quality <- ifelse(train_norm_dummy_df$binned_quality == "Low", 1, 0)
valid_norm_dummy_df$high_quality <- ifelse(valid_norm_dummy_df$binned_quality == "High", 1, 0)
valid_norm_dummy_df$intermediate_quality <- ifelse(valid_norm_dummy_df$binned_quality == "Intermediate", 1, 0)
valid_norm_dummy_df$low_quality <- ifelse(valid_norm_dummy_df$binned_quality == "Low", 1, 0)
test_norm_dummy_df$high_quality <- ifelse(test_norm_dummy_df$binned_quality == "High", 1, 0)
test_norm_dummy_df$intermediate_quality <- ifelse(test_norm_dummy_df$binned_quality == "Intermediate", 1, 0)
test_norm_dummy_df$low_quality <- ifelse(test_norm_dummy_df$binned_quality == "Low", 1, 0)
set.seed(1)
add_train_df = rwo(train_df, 400, "binned_quality") # Generation of 400 instances
os_train_df = rbind(train_df, add_train_df) # Combining the new instances to the training set
os_train_norm_df = os_train_df
#use PreProcess() from the caret package and predict() to normalize numerical variables
os_norm_values = preProcess(os_train_df[,-c(11)], method = "range")
os_train_norm_df[,-c(11)] = predict(os_norm_values, os_train_df[,-c(11)])
# Initialize oversampled normalized training set with dummies to the oversampled normalized one
os_train_norm_dummy_df <- os_train_norm_df
os_train_norm_dummy_df$high_quality <- ifelse(os_train_norm_dummy_df$binned_quality == "High", 1, 0)
os_train_norm_dummy_df$intermediate_quality <- ifelse(os_train_norm_dummy_df$binned_quality == "Intermediate", 1, 0)
os_train_norm_dummy_df$low_quality <- ifelse(os_train_norm_dummy_df$binned_quality == "Low", 1, 0)
#perform knn classification on the test set using best k = 1
best_knn_pred = knn(train = train_norm_df[,-11], test = test_norm_df[,-11], cl = train_norm_df[,11], k = 2)
confusionMatrix(best_knn_pred, test_norm_df[,11])#create corresponding confusion matrix
kappa_best_knn = confusionMatrix(best_knn_pred, test_norm_df[,11])$overall[2]
kappa_best_knn
low_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[1,1]
bal_acc_best_knn = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_best_knn
os_log_reg = multinom(binned_quality ~ ., data = os_train_df)
summary(os_log_reg)
os_log_prob = predict(os_log_reg, newdata = test_df, type = "p")
os_log_pred = data.frame("pred" = colnames(os_log_prob)[apply(os_log_prob,1,which.max)])
os_log_pred$pred = as.factor(os_log_pred$pred)
confusionMatrix(os_log_pred$pred, test_df[,11])
kappa_logist = confusionMatrix(os_log_pred$pred, test_df[,11])$overall[2]
kappa_logist
low_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[1,1]
bal_acc_logist = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_logist
os_nb_model = naiveBayes (binned_quality ~ ., data = os_train_df)
os_nb_model
os_nb_pred = predict(os_nb_model, newdata = test_df, type = "class")
confusionMatrix(os_nb_pred, test_df[,11])
kappa_bayes = confusionMatrix(os_nb_pred, test_df[,11])$overall[2]
kappa_bayes
low_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[1,1]
bal_acc_bayes = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_bayes
set.seed(1)
tree1 <- rpart(binned_quality ~ ., data=os_train_df, method = "class", control = rpart.control(cp = 0, minsplit = 1, minbucket = 1, xval = 5))
# Look at the minimum standard error
printcp(tree1)
which.min(tree1$cptable[, 4])
# Take the cp associated with the minimum standard error to prune the tree:
set.seed(1)
pruned_tree1 <- prune(tree1, cp = tree1$cptable[which.min(tree1$cptable[, "xerror"]), "CP"])
prp(pruned_tree1)
# If we want to look at the most important variables:
pruned_tree1$variable.importance
# We can now predict the outcome:
pruned_tree1_pred_test <- predict(pruned_tree1, test_df, type="class")
pruned_tree1_cm <- confusionMatrix(pruned_tree1_pred_test, test_df$binned_quality)
pruned_tree1_cm
kappa_pruned_tree1 = pruned_tree1_cm$overall[2]
kappa_pruned_tree1
low_sensitivity = pruned_tree1_cm$byClass[3,1]
intermediate_sensitivity = pruned_tree1_cm$byClass[2,1]
high_sensitivity = pruned_tree1_cm$byClass[1,1]
bal_acc_pruned_tree1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_pruned_tree1
set.seed(1)
boost1 <- boosting(binned_quality ~ ., data=os_train_df, control = rpart.control(xval = 5))
boost1_pred_test <- predict(boost1, test_df, type="class")
boost1.cm <- confusionMatrix(as.factor(boost1_pred_test$class), test_df$binned_quality)
boost1.cm
kappa_boost1 = boost1.cm$overall[2]
kappa_boost1
low_sensitivity = boost1.cm$byClass[3,1]
intermediate_sensitivity = boost1.cm$byClass[2,1]
high_sensitivity = boost1.cm$byClass[1,1]
bal_acc_boost1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_boost1
set.seed(1)
bag1 <- bagging(binned_quality ~ ., data=os_train_df, control = rpart.control(xval = 5))
bag1_pred_test <- predict(bag1, test_df, type="class")
bag1.cm <- confusionMatrix(as.factor(bag1_pred_test$class), test_df$binned_quality)
bag1.cm
kappa_bag1 = bag1.cm$overall[2]
kappa_bag1
low_sensitivity = bag1.cm$byClass[3,1]
intermediate_sensitivity = bag1.cm$byClass[2,1]
high_sensitivity = bag1.cm$byClass[1,1]
bal_acc_bag1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_bag1
set.seed(1)
rf1 <- randomForest(os_train_df[-11], os_train_df$binned_quality, control = rpart.control(xval = 5))
rf1_pred_test <- predict(rf1, test_df, type="class")
rf1.cm <- confusionMatrix(rf1_pred_test, test_df$binned_quality)
rf1.cm
kappa_rf1 = rf1.cm$overall[2]
kappa_rf1
low_sensitivity = rf1.cm$byClass[3,1]
intermediate_sensitivity = rf1.cm$byClass[2,1]
high_sensitivity = rf1.cm$byClass[1,1]
bal_acc_rf1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_rf1
set.seed(1)
nn1 <- neuralnet(high_quality + intermediate_quality + low_quality ~ ., data = train_norm_dummy_df[, -11], hidden = 7, linear.output = FALSE, threshold = 0.1)
test_pred_nn1 <- data.frame(predict(nn1, test_norm_dummy_df[, -c(11, 12, 13, 14)]))
names(test_pred_nn1)[1:3] <- c("High", "Intermediate", "Low")
test_pred_nn1$Prediction <- NA
for(j in 1:length(test_pred_nn1$High)) {
test_pred_nn1[j, 4] <- names(which.max(test_pred_nn1[j, 1:3]))
}
nn1.cm <- confusionMatrix(as.factor(test_pred_nn1$Prediction), test_norm_df$binned_quality)
nn1.cm
kappa_nn1 = nn1.cm$overall[2]
kappa_nn1
low_sensitivity = nn1.cm$byClass[3,1]
intermediate_sensitivity = nn1.cm$byClass[2,1]
high_sensitivity = nn1.cm$byClass[1,1]
bal_acc_nn1 = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_nn1
ensemble_pred_df = data.frame("actual_value" = test_df$binned_quality,
"knn_pred" = best_knn_pred,
"log_pred" = os_log_pred$pred,
"nb_pred" = os_nb_pred,
"tree_pred" = pruned_tree1_pred_test,
"boosting_pred" = boost1_pred_test,
"bagging_pred" = bag1_pred_test,
"rf_pred" = rf1_pred_test,
"nnet_pred" = as.factor(test_pred_nn1$Prediction))
test_df$binned_quality
best_knn_pred
os_log_pred$pred
os_nb_pred
pruned_tree1_pred_test
boost1_pred_test
test_df$binned_quality
best_knn_pred
os_log_pred$pred
os_nb_pred
ensemble_pred_df = data.frame("actual_value" = test_df$binned_quality,
"knn_pred" = best_knn_pred,
"log_pred" = os_log_pred$pred,
"nb_pred" = os_nb_pred,
"tree_pred" = pruned_tree1_pred_test,
"boosting_pred" = as.factor(boost1_pred_test$class),
"bagging_pred" = as.factor(bag1_pred_test$class),
"rf_pred" = rf1_pred_test,
"nnet_pred" = as.factor(test_pred_nn1$Prediction))
head(ensemble_pred_df)
ensemble_pred_df = data.frame("actual_value" = test_df$binned_quality,
"knn_pred" = best_knn_pred,
"log_pred" = os_log_pred$pred,
"nb_pred" = os_nb_pred,
"tree_pred" = pruned_tree1_pred_test,
"boosting_pred" = as.factor(boost1_pred_test$class),
"bagging_pred" = as.factor(bag1_pred_test$class),
"rf_pred" = rf1_pred_test,
"nnet_pred" = as.factor(test_pred_nn1$Prediction))
ensemble_pred_df$majority_vote = apply(ensemble_pred_df[2:9], 1, function(x) names(which.max(table(x))))
head(ensemble_pred_df)
#perform knn classification on the test set using best k = 1
best_knn_pred = knn(train = train_norm_df[,-11], test = test_norm_df[,-11], cl = train_norm_df[,11], k = 2, prob = T)
confusionMatrix(best_knn_pred, test_norm_df[,11])#create corresponding confusion matrix
kappa_best_knn = confusionMatrix(best_knn_pred, test_norm_df[,11])$overall[2]
kappa_best_knn
low_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[1,1]
bal_acc_best_knn = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
bal_acc_best_knn
attr(best_knn_pred, "prob")
best_knn_pred
head(ensemble_pred_df)
attr(best_knn_pred, "prob")
ensembles_pred_df = data.frame("actual_value" = test_df$binned_quality,
"knn_pred" = best_knn_pred,
"log_pred" = os_log_pred$pred,
"nb_pred" = os_nb_pred,
"tree_pred" = pruned_tree1_pred_test,
"boosting_pred" = as.factor(boost1_pred_test$class),
"bagging_pred" = as.factor(bag1_pred_test$class),
"rf_pred" = rf1_pred_test,
"nnet_pred" = as.factor(test_pred_nn1$Prediction))
ensembles_pred_df$majority_vote = apply(ensembles_pred_df[2:9], 1, function(x) names(which.max(table(x))))
head(ensembles_pred_df)
