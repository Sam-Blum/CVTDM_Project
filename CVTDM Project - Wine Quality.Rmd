---
title: "CVTDM Project - Wine Quality"
author: "Sam Blum and Mathis Da Silva"
date: "25/11/2021"
output: html_document
---

```{r, warning = FALSE, message = FALSE}
rm(list = ls())

library(naniar)
library(ggplot2)
library(reshape2)
library(magrittr)
library(dplyr)
library(car)
library(GGally)
library(viridis)
library(caret)
library(ggplot2)
library(cowplot)
library(FNN)
library(MASS)
library(rpart)
library(rpart.plot)
library(adabag)
library(randomForest)
library(imbalance)
library(e1071)
library(neuralnet)

# setwd("~/GitHub/CVTDM_Project")
wine = read.csv(file = "winequality-white.csv", header = T, sep = ";")
```

### Data exploration

```{r, warning = FALSE}
dim(wine)

sapply(wine, function(x) length(unique(x)))

wine$binned_quality = as.factor(ifelse(wine$quality < 5, 'Low',
                                ifelse(wine$quality >= 5 & wine$quality < 7, "Intermediate",
                                ifelse(wine$quality >= 7, "High", "None"))))

wine$quality = as.factor(wine$quality)

summary(wine)

sapply(wine[,-c(12,13)], sd)

str(wine)

gg_miss_var(wine, show_pct = TRUE)
```

```{r, warning= FALSE}
boxplots = ggplot(data = melt(wine[,-13], "quality"), aes(quality, value, group = quality)) + 
  geom_boxplot(fill = "transparent", color = "black") + 
  facet_wrap(~variable, scale = "free", ncol = 3) +
  theme_classic()

boxplots
```

```{r}
# Histograms for each variable
par(mfrow=c(2, 3))
for (i in 1:11) {
  hist(wine[, i], main = c("Histogram for", names(wine[i])), xlab=names(wine[i]))
  abline(v = mean(wine[, i]), col = 1, lwd = 2)
  abline(v = median(wine[, i]), col = 2, lwd = 2)
}

#Barplot for quality
par(mfrow=c(1, 1))
barplot(table(wine$binned_quality), main = c("Histogram for quality", names(wine$binned_quality)), xlab=names(wine$binned_quality))
```

```{r, warning= FALSE}
alllogwine = wine
alllogwine[,-c(12,13)] = lapply(alllogwine[,-c(12,13)], log) #log transform all variables except quality and binned quality

boxplots = ggplot(data = melt(alllogwine[,-13], "quality"), aes(quality, value, group = quality)) + 
  geom_boxplot(fill = "transparent", color = "black") + 
  facet_wrap(~variable, scale = "free", ncol = 3) +
  theme_classic()

boxplots
```

```{r}
# Gives histogram for log
par(mfrow=c(2, 3))
for (i in 1:11) {
  hist(alllogwine[, i], main = c("Histogram for", names(alllogwine[i])), xlab=names(alllogwine[i]))
  abline(v = mean(alllogwine[, i]), col = 1, lwd = 2)
  abline(v = median(alllogwine[, i]), col = 2, lwd = 2)
}
```

```{r, warning = FALSE}
cor_mat = round(cor(wine[,-c(12,13)]),2) 
cor_mat2 = melt(cor_mat)

ggplot(data = cor_mat2, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(Var2, Var1, label = value), color = "white", size = 3) +
  labs(title = "Heatmap of the correlation table") +
  theme(axis.text.x = element_text(angle=90))
```

```{r, warning = FALSE}
wine$quality = as.numeric(wine$quality)

model = lm(quality ~., data = wine[,-13])
vif(model)

model2 = lm(quality ~., data = wine[,-c(8,13)])
vif(model2)

wine$quality = as.factor(wine$quality)
```

```{r}
ggparcoord(wine, columns = 1:11, groupColumn = 13, showPoints = TRUE, alphaLines = 0.3, scale = "uniminmax") + scale_color_viridis(discrete = TRUE) + theme(axis.text.x = element_text(angle = 90))
```

### Data pre-processing

```{r, warning = FALSE}
logwine = wine[,-c(8,12)] #drop density and quality
logwine[,-c(3,7,8,11)] = lapply(logwine[,-c(3,7,8,11)], log) #log transform all variables except citric.acid, total.sulfure.dioxide, pH and binned_quality
head(logwine) 
```

### Data partitioning

```{r, warning = FALSE}
set.seed(1)
train_index = createDataPartition(logwine$binned_quality, p = .5, list = FALSE)
train_df = logwine[train_index,]
valid_test_df = logwine[-train_index,]
valid_index = createDataPartition(valid_test_df$binned_quality, p = .6, list = FALSE)
valid_df = valid_test_df[valid_index,]
test_df = valid_test_df[-valid_index,]
```

### Data normalization

```{r, warning = FALSE}
#initialize normalized training and validation data frames to the original ones
train_norm_df = train_df
valid_norm_df = valid_df
test_norm_df = test_df

#use PreProcess() from the caret package and predict() to normalize numerical variables
norm_values = preProcess(train_df[,-c(11)], method = "range")
train_norm_df[,-c(11)] = predict(norm_values, train_df[,-c(11)])
valid_norm_df[,-c(11)] = predict(norm_values, valid_df[,-c(11)])
test_norm_df[,-c(11)] = predict(norm_values, test_df[,-c(11)])
```

### KNN

```{r, warning = FALSE}
#initialize a new data frame with three columns: k, accuracy, and balanced_accuracy
best_k_df = data.frame(k = seq(1, 50, 1), kappa = rep(0,50), balanced_accuracy = rep(0,50))

#perform knn on the validation set using different k then store accuracy and balanced accuracy for each k in the data frame
for(i in 1:50) {
  knn_pred = knn(train = train_norm_df[,-11], test = valid_norm_df[,-11], cl = train_norm_df[,11], k = i)
  best_k_df[i, 2] = confusionMatrix(knn_pred, valid_norm_df[,11])$overall[2]
  low_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[3,1]
  intermediate_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[2,1]
  high_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[1,1]
  best_k_df[i, 3] = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
}

kappa_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=kappa), color="red") + theme_classic()
balanced_accuray_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=balanced_accuracy), color="blue") + theme_classic()

plot_grid(kappa_plot, balanced_accuray_plot, ncol = 1, align = "v")

which.max(best_k_df$kappa)#best k based on kappa
which.max(best_k_df$balanced_accuracy)#best k based on balanced accuracy
```

```{r, warning = FALSE}
#perform knn classification on the test set using best k = 1
best_knn_pred = knn(train = train_norm_df[,-11], test = test_norm_df[,-11], cl = train_norm_df[,11], k = 1)
confusionMatrix(best_knn_pred, test_norm_df[,11])#create corresponding confusion matrix 

kappa = confusionMatrix(best_knn_pred, test_norm_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```

### Classification tree

(1) Full grown tree:
```{r}
set.seed(1)
tree1 <- rpart(binned_quality ~ ., data=train_df, method = "class", control = rpart.control(cp = 0, minsplit = 1, minbucket = 1, xval = 5))

# Look at the minimum standard error
printcp(tree1)
which.min(tree1$cptable[, 4])

# Take the cp associated with the minimum standard error to prune the tree:
set.seed(1)
pruned_tree1 <- prune(tree1, cp = tree1$cptable[which.min(tree1$cptable[, "xerror"]), "CP"])
prp(pruned_tree1)

# If we want to look at the most important variables:
pruned_tree1$variable.importance

# We can now predict the outcome:
pruned_tree1_pred_valid <- predict(pruned_tree1, valid_df, type="class")
pruned_tree_cm <- confusionMatrix(pruned_tree1_pred_valid, valid_df$binned_quality)
pruned_tree_cm
```

(2) Boosted tree:
```{r}
set.seed(1)
boost <- boosting(binned_quality ~ ., data=train_df)
boost_tree1_pred_valid <- predict(boost, valid_df, type="class")
boost.cm <- confusionMatrix(as.factor(boost_tree1_pred_valid$class), valid_df$binned_quality)
boost.cm
```

(3) Bagged tree:
```{r}
set.seed(1)
bag <- bagging(binned_quality ~ ., data=train_df)
bag_tree1_pred_valid <- predict(bag, valid_df, type="class")
bag.cm <- confusionMatrix(as.factor(bag_tree1_pred_valid$class), valid_df$binned_quality)
bag.cm
```

(4) Random Forest:
```{r}
set.seed(1)
rf1 <- randomForest(train_df[-11], train_df$binned_quality)
rf1_pred_valid <- predict(rf1, valid_df, type="class")
rf1.cm <- confusionMatrix(rf1_pred_valid, valid_df$binned_quality)
rf1.cm
```

### Neural Nets

```{r}
# 1 node
set.seed(1)
nn1 <- neuralnet(binned_quality ~ ., data = train_norm_df, hidden = 2, linear.output = FALSE)
# nn1$weights
# plot(nn1, rep="best", cex=0.8)

valid_pred_nn1 <- data.frame(predict(nn1, valid_norm_dummy_df[, -11]))
names(valid_pred_nn1)[1:3] <- c("High", "Intermediate", "Low")
valid_pred_nn1$Prediction <- 0

for(i in 1:length(valid_pred_nn1$High)) {
  valid_pred_nn1[i, 4] <- names(which.max(valid_pred_nn1[i, 1:3]))
}

confusionMatrix(as.factor(valid_pred_nn1$Prediction), valid_norm_df$binned_quality)
```

### Ordinal logistic regression 

```{r, warning = FALSE}
log_reg = polr(binned_quality ~ ., data = train_df)
summary(log_reg)
```

```{r, warning = FALSE}
log_prob = predict(log_reg, newdata = test_df, type = "p")

log_pred = data.frame("pred" = colnames(log_prob)[apply(log_prob,1,which.max)])
log_pred$pred = as.factor(log_pred$pred)

confusionMatrix(log_pred$pred, test_df[,11])

kappa = confusionMatrix(log_pred$pred, test_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(log_pred$pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(log_pred$pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(log_pred$pred, test_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```

### Naive Bayes

```{r, warning = FALSE}
nb_model = naiveBayes (binned_quality ~ ., data = train_df)
nb_model
```

```{r, warning = FALSE}
nb_pred = predict(nb_model, newdata = test_df, type = "class")
confusionMatrix(nb_pred, test_df[,11])

kappa = confusionMatrix(nb_pred, test_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(nb_pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(nb_pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(nb_pred, test_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```

### Oversampled KNN 

```{r, warning = FALSE}
set.seed(1)
new_train_df = rwo(train_df, 400, "binned_quality")
os_train_df = rbind(train_df, new_train_df)
```

```{r, warning = FALSE}
os_train_norm_df = os_train_df

#use PreProcess() from the caret package and predict() to normalize numerical variables
os_norm_values = preProcess(os_train_df[,-c(11)], method = "range")
os_train_norm_df[,-c(11)] = predict(os_norm_values, os_train_df[,-c(11)])
```

```{r, warning = FALSE}
#initialize a new data frame with three columns: k, accuracy, and balanced_accuracy
best_k_df = data.frame(k = seq(1, 50, 1), kappa = rep(0,50), balanced_accuracy = rep(0,50))

#perform knn on the validation set using different k then store accuracy and balanced accuracy for each k in the data frame
for(i in 1:50) {
  knn_pred = knn(train = os_train_norm_df[,-11], test = valid_norm_df[,-11], cl = os_train_norm_df[,11], k = i)
  best_k_df[i, 2] = confusionMatrix(knn_pred, valid_norm_df[,11])$overall[2]
  low_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[3,1]
  intermediate_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[2,1]
  high_sensitivity = confusionMatrix(knn_pred, valid_norm_df[,11])$byClass[1,1]
  best_k_df[i, 3] = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
}

kappa_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=kappa), color="red") + theme_classic()
balanced_accuray_plot = ggplot(data= best_k_df) + geom_line(aes(x=k,y=balanced_accuracy), color="blue") + theme_classic()

plot_grid(kappa_plot, balanced_accuray_plot, ncol = 1, align = "v")

which.max(best_k_df$kappa)#best k based on accuracy
which.max(best_k_df$balanced_accuracy)#best k based on balanced accuracy
```

```{r, warning = FALSE}
#perform knn classification on the test set using best k = 2
best_knn_pred = knn(train = os_train_norm_df[,-11], test = test_norm_df[,-11], cl = os_train_norm_df[,11], k = 2)
confusionMatrix(best_knn_pred, test_norm_df[,11])#create corresponding confusion matrix 

kappa = confusionMatrix(best_knn_pred, test_norm_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(best_knn_pred, test_norm_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```

### Oversampled ordinal logistic regression

```{r, warning = FALSE}
os_log_reg = polr(binned_quality ~ ., data = os_train_df)
summary(os_log_reg)
```

```{r, warning = FALSE}
os_log_prob = predict(os_log_reg, newdata = test_df, type = "p")

os_log_pred = data.frame("pred" = colnames(os_log_prob)[apply(os_log_prob,1,which.max)])
os_log_pred$pred = as.factor(os_log_pred$pred)

confusionMatrix(os_log_pred$pred, test_df[,11])

kappa = confusionMatrix(os_log_pred$pred, test_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_log_pred$pred, test_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```

### Oversampled naive Bayes

```{r, warning = FALSE}
os_nb_model = naiveBayes (binned_quality ~ ., data = os_train_df)
os_nb_model
```

```{r, warning = FALSE}
os_nb_pred = predict(os_nb_model, newdata = test_df, type = "class")
confusionMatrix(os_nb_pred, test_df[,11])

kappa = confusionMatrix(os_nb_pred, test_df[,11])$overall[2]
kappa

low_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[3,1]
intermediate_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[2,1]
high_sensitivity = confusionMatrix(os_nb_pred, test_df[,11])$byClass[1,1]

balanced_accuracy = (low_sensitivity + intermediate_sensitivity + high_sensitivity) / 3
balanced_accuracy
```